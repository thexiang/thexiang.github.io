{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "# test code\n",
    "cat testfile | ./mapper.py | sort | ./reducer.py\n",
    "\n",
    "# run a job\n",
    "hs mapper.py reducer.py input_folder output_folder\n",
    "\n",
    "# view the results\n",
    "hadoop fs -cat output_folder/part-00000 | less\n",
    "\n",
    "# retrieve the results\n",
    "hadoop fs -get output_folder/part-00000 results.txt\n",
    "\n",
    "# delete a folder\n",
    "hadoop fs -rm -r delete_folder\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\t\"\"\t\"\"\t\"\"\t\"This is one sentence\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"Also one sentence!\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"Three\n",
      "lines, one sentence\n",
      "\"\t\"\"\r\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "# To run this code on the actual data, please download the additional dataset.\n",
    "# You can find instructions in the course materials (wiki) and in the instructor notes.\n",
    "# There are some things in this data file that are different from what you saw\n",
    "# in Lesson 3. The dataset is more complicated and closer to what you might\n",
    "# see in the real world. It was generated by exporting data from a SQL database.\n",
    "# \n",
    "# The data in at least one of the fields (the body field) can include newline\n",
    "# characters, and all the fields are enclosed in double quotes. Therefore, we\n",
    "# will need to process the data file in a way other than using split(\",\"). To do this, \n",
    "# we have provided sample code for using the csv module of Python. Each 'line'\n",
    "# will be a list that contains each field in sequential order.\n",
    "# \n",
    "# In this exercise, we are interested in the field 'body' (which is the 5th field, \n",
    "# line[4]). The objective is to count the number of forum nodes where 'body' either \n",
    "# contains none of the three punctuation marks: period ('.'), exclamation point ('!'), \n",
    "# question mark ('?'), or else 'body' contains exactly one such punctuation mark as the \n",
    "# last character. There is no need to parse the HTML inside 'body'. Also, do not pay\n",
    "# special attention to newline characters.\n",
    "\n",
    "def mapper():\n",
    "    reader = csv.reader(sys.stdin, delimiter='\\t')\n",
    "    writer = csv.writer(sys.stdout, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    for line in reader:\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        if ('.' not in line[4][:-1] and '!' not in line[4][:-1] and '?' not in line[4][:-1]):\n",
    "            writer.writerow(line)\n",
    "\n",
    "\n",
    "\n",
    "test_text = \"\"\"\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"This is one sentence\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"Also one sentence!\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"Hey!\\nTwo sentences!\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"One. Two! Three?\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"One Period. Two Sentences\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"Three\\nlines, one sentence\\n\\\"\\t\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# This function allows you to test the mapper with the provided test string\n",
    "def main():\n",
    "    import StringIO\n",
    "    sys.stdin = StringIO.StringIO(test_text)\n",
    "    mapper()\n",
    "    sys.stdin = sys.__stdin__\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\t\"\"\t\"\"\t\"\"\t\"22\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"333\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"4444\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"55555\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"666666\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"7777777\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"88888888\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"999999999\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"1000000000\"\t\"\"\r\n",
      "\"\"\t\"\"\t\"\"\t\"\"\t\"11111111111\"\t\"\"\r\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "\"\"\"\n",
    "Your mapper function should print out 10 lines containing longest posts, sorted in\n",
    "ascending order from shortest to longest.\n",
    "Please do not use global variables and do not change the \"main\" function.\n",
    "\"\"\"\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "\n",
    "def mapper():\n",
    "    reader = csv.reader(sys.stdin, delimiter='\\t')\n",
    "    writer = csv.writer(sys.stdout, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    \n",
    "    # simple approach: use a list to store the posts, with 0 being the longest and 9 being the shortest\n",
    "    top10 = []\n",
    "\n",
    "    for line in reader:\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        top10.append(line)\n",
    "        if len(top10) > 10:\n",
    "            top10.sort(key=lambda x: len(x[4]), reverse=True)\n",
    "            del top10[10]\n",
    "            \n",
    "    for line in reversed(top10):\n",
    "        writer.writerow(line)\n",
    "\n",
    "\n",
    "\n",
    "test_text = \"\"\"\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"333\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"88888888\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"1\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"11111111111\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"1000000000\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"22\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"4444\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"666666\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"55555\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"999999999\\\"\\t\\\"\\\"\n",
    "\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"\\\"\\t\\\"7777777\\\"\\t\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# This function allows you to test the mapper with the provided test string\n",
    "def main():\n",
    "    import StringIO\n",
    "    sys.stdin = StringIO.StringIO(test_text)\n",
    "    mapper()\n",
    "    sys.stdin = sys.__stdin__\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# split on white space and: .,!?:;\"()<>[]#$=-/\n",
    "\n",
    "reader = csv.reader(sys.stdin, delimiter='\\t')\n",
    "writer = csv.writer(sys.stdout, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "for line in reader:\n",
    "    words = re.split('\\s*[,.!?:;\"()<>\\[\\]#$=\\-/\\s]+\\s*',line[4].lstrip().lower()+' ')\n",
    "    #print words\n",
    "    for word in words[:-1]:\n",
    "        #writer.writerow([word, line[0]])\n",
    "        print word, '\\t', line[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "\n",
    "# the input is of the format: word \\t node_id\n",
    "\n",
    "old_word = None\n",
    "count = 0\n",
    "id_set = set()\n",
    "\n",
    "for line in sys.stdin:\n",
    "    data = line.strip().split(\"\\t\")\n",
    "    if len(data) != 2:\n",
    "        # Something has gone wrong. Skip this line.\n",
    "        continue\n",
    "\n",
    "    # same word --> add to the count\n",
    "    if old_word and old_word == data[0]:\n",
    "        count += 1\n",
    "        id_set.add(data[1])\n",
    "        \n",
    "    # new word\n",
    "    else:\n",
    "        # not the first word\n",
    "        if old_word:\n",
    "            print old_word, '\\t', count, '\\t', sorted(id_set)\n",
    "            \n",
    "        # reset the old_word and the count\n",
    "        old_word = data[0]\n",
    "        count = 1\n",
    "        id_set = set()\n",
    "\n",
    "# the last word\n",
    "if old_word != None:\n",
    "    print old_word, '\\t', count, '\\t', sorted(id_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# weekday = datetime.strptime(date, '%Y-%m-%d').weekday()\n",
    "\n",
    "for line in sys.stdin:\n",
    "    data = line.strip().split('\\t')\n",
    "    if len(data) == 6:\n",
    "        # print the weekday and the sale amount\n",
    "        weekday = datetime.strptime(data[0], '%Y-%m-%d').weekday()\n",
    "        print \"{0}\\t{1}\".format(weekday, data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "\n",
    "# the input is of the format: day_of_week \\t sale_amount\n",
    "\n",
    "old_day = None\n",
    "count = 0\n",
    "sales = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    data = line.strip().split(\"\\t\")\n",
    "    if len(data) != 2:\n",
    "        # Something has gone wrong. Skip this line.\n",
    "        continue\n",
    "\n",
    "    # same day --> add to the sales count\n",
    "    if old_day and old_day == data[0]:\n",
    "        count += 1\n",
    "        sales += float(data[1])\n",
    "        \n",
    "    # new word\n",
    "    else:\n",
    "        # not the first word\n",
    "        if old_day:\n",
    "            print old_day, '\\t', sales/count\n",
    "            \n",
    "        # reset the old_word and the count\n",
    "        old_day = data[0]\n",
    "        count = 1\n",
    "        sales = float(data[1])\n",
    "\n",
    "# the last word\n",
    "if old_day != None:\n",
    "    print old_day, '\\t', sales/count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combiners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# weekday = datetime.strptime(date, '%Y-%m-%d').weekday()\n",
    "\n",
    "for line in sys.stdin:\n",
    "    data = line.strip().split('\\t')\n",
    "    if len(data) == 6:\n",
    "        # print the weekday and the sale amount\n",
    "        weekday = datetime.strptime(data[0], '%Y-%m-%d').weekday()\n",
    "        print \"{0}\\t{1}\".format(weekday, data[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducer & Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "\n",
    "# the input is of the format: day_of_week \\t sale_amount\n",
    "\n",
    "old_day = None\n",
    "sales = 0\n",
    "\n",
    "for line in sys.stdin:\n",
    "    data = line.strip().split(\"\\t\")\n",
    "    if len(data) != 2:\n",
    "        # Something has gone wrong. Skip this line.\n",
    "        continue\n",
    "\n",
    "    # same day --> add to the sales\n",
    "    if old_day and old_day == data[0]:\n",
    "        sales += float(data[1])\n",
    "        \n",
    "    # new word\n",
    "    else:\n",
    "        # not the first word\n",
    "        if old_day:\n",
    "            print old_day, '\\t', sales\n",
    "            \n",
    "        # reset the old_word and the sales\n",
    "        old_day = data[0]\n",
    "        sales = float(data[1])\n",
    "\n",
    "# the last word\n",
    "if old_day != None:\n",
    "    print old_day, '\\t', sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\"\"\"\n",
    "Your goal for this task is to write mapper and reducer code \n",
    "that will combine some of the forum and user data. \n",
    "In relational algebra, this is known as a join operation. \n",
    "At the moment, this is not an auto-gradable exercise, but instructions below are given on how to test your code on your machine. \n",
    "\n",
    "The goal is to have the output from the reducer with the following fields for each forum post: \n",
    "\n",
    "\"id\"  \"title\"  \"tagnames\"  \"author_id\"  \"node_type\"  \"parent_id\"  \"abs_parent_id\"  \"added_at\" \n",
    "\"score\"  \"reputation\"  \"gold\"  \"silver\"  \"bronze\"\n",
    "\n",
    "FROM forum_node: 0,1,2,3, 5,6,7,8,9\n",
    "    \"id\"\t\"title\"\t\"tagnames\"\t\"author_id\"\t\"BODY\"\t\"node_type\"\t\"parent_id\"\t\"abs_parent_id\"\t\"added_at\"\t\n",
    "    \"score\"\n",
    "\n",
    "FROM forum_users:\n",
    "    \"user_ptr_id\"\t\"reputation\"\t\"gold\"\t\"silver\"\t\"bronze\"\n",
    "\n",
    "Note that for each post we have taken some of the information describing the post, \n",
    "and joined it with user information. The body of the post is not included in the final output. \n",
    "The reason is that it is difficult to handle a multiline body, as it might be split on separate \n",
    "lines during the intermediate steps Hadoop performs - shuffle and sort.   \n",
    "\n",
    "Your mapper code should take in records from both forum_node and forum_users. \n",
    "It needs to keep, for each record, those fields that are needed for the final output given above. \n",
    "In addition, mapper needs to add some text (e.g. \"A\" and \"B\") to mark where each output comes from \n",
    "(user information vs forum post information). Example output from mapper is:\n",
    "\n",
    "\"12345\"  \"A\"  \"11\"  \"3\"  \"4\"  \"1\"\n",
    "\"12345\"  \"B\"   \"6336\" \"Unit 1: Same Value Q\"  \"cs101 value same\"  \"question\"  \"\\N\"  \"\\N\"  \"2012-02-25 08:09:06.787181+00\"  \"1\" \n",
    "  \n",
    "The first line originally comes from the forum_users input. It is from a student with user id: 12345 - the mapper key. \n",
    "The next field is the marker A specifying that the record comes from forum_users. \n",
    "What follows is the remaining information user information. \n",
    "\n",
    "The second line originally comes from the forum_node input. \n",
    "It also starts with the student id (mapper key) followed by a marker B and the information about the forum post.  \n",
    "   \n",
    "The mapper key for both types of records is the student ID: \n",
    "\"user_ptr_id\" from \"forum_users\" or  \"author_id\" from \"forum_nodes\" file. \n",
    "Remember that during the sort and shuffle phases records will be grouped based on the student ID (12345 in our example). \n",
    "You can use that to process and join the records appropriately in the reduce phase. \n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "def mapper():\n",
    "    reader = csv.reader(sys.stdin, delimiter='\\t')\n",
    "    writer = csv.writer(sys.stdout, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    for line in reader:\n",
    "        # user data\n",
    "        if len(line)==5:\n",
    "            if line[0] != 'user_ptr_id':\n",
    "                writer.writerow(line[0:1]+['A']+line[1:])\n",
    "            \n",
    "        # post data\n",
    "        else:\n",
    "            if line[0] != 'id':\n",
    "                writer.writerow(line[0:1]+['B']+line[1:4]+line[5:10])\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    mapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "# Here you will be able to combine the values that come from 2 sources\n",
    "# Value that starts with A will be the user data\n",
    "# Values that start with B will be forum node data\n",
    "\n",
    "'''\n",
    "FROM forum_node: 0,1,2,3, 5,6,7,8,9\n",
    "    \"id\"\t\"B\" \"title\"\t\"tagnames\"\t\"author_id\"\t\"node_type\"\t\"parent_id\"\t\"abs_parent_id\"\t\"added_at\"\t\"score\"\n",
    "\n",
    "FROM forum_users:\n",
    "    \"user_ptr_id\"\t\"A\" \"reputation\"\t\"gold\"\t\"silver\"\t\"bronze\"\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "def reducer():\n",
    "    writer = csv.writer(sys.stdout, delimiter='\\t', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "    user = []\n",
    "    \n",
    "    for line in sys.stdin:\n",
    "        data = line.strip().split('\\t')\n",
    "        if len(data) != 6 and len(data) != 10:\n",
    "            # something is wrong\n",
    "            pass\n",
    "            \n",
    "        # new user\n",
    "        if user and user[0] != data[0]:\n",
    "            user = data\n",
    "            continue\n",
    "            \n",
    "        # posts by the user\n",
    "        writer.writerow(data[0:1]+data[2:]+user[2:])\n",
    "        \n",
    "        \n",
    "if __name__=='__main__':\n",
    "    reducer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
